{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ea5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1d2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + np.random.normal(0, 0.1, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00d1daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model)**2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f7242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x) # flattens the matrices\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x) #number of x-variables, datapoints\n",
    "    l = int((n+1)*(n+2)/2)     # Number of elements in beta - parameters, features\n",
    "    X = np.ones((N,l)) #Making a matrix of dimentions given by the number of variables and number of parameters\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        q = int((i)*(i+1)/2)\n",
    "        for k in range(i+1):\n",
    "            X[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d58cfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_beta(X, z): \n",
    "    XT = X.T\n",
    "    XTXinv = np.linalg.pinv(np.matmul(XT, X))\n",
    "    XTz = np.matmul(XT, z)\n",
    "    beta = np.matmul(XTXinv, XTz)\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad4ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "size = 2000\n",
    "noise = 0.05 # Level of noise\n",
    "x = np.arange(0, 1, 1/size)\n",
    "y = np.arange(0, 1, 1/size)\n",
    "#x, y = np.meshgrid(x,y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "z += (np.random.randn(size)*noise) #Added noise\n",
    "print(len(x), len(y), len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b1a97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "'''def bootstrap(x, z, x_test, z_test, iterations = 100):\n",
    "    MSEs = np.zeros(iterations) \n",
    "    R2s = np.zeros(iterations) \n",
    "    z_preds= []\n",
    "    for i in range(iterations):\n",
    "        bt_x, bt_z = resample(x, z)\n",
    "        beta = find_beta(bt_x, bt_z) #Finding beta with new x train and z train\n",
    "        z_pred = x_test @ beta #predict z with x_test\n",
    "        z_preds.append(z_pred)\n",
    "        mse = MSE(z_test, z_pred)\n",
    "        r2 = R2(z_test, z_pred) # getting statistics of prediction in current bootstrap\n",
    "        MSEs[i] = mse\n",
    "        R2s[i] = r2\n",
    "    \n",
    "    zpreds = np.mean(z_preds)\n",
    "    bt_err = np.mean( np.mean((z_test - z_preds)**2, axis=1, keepdims=True))\n",
    "    bt_bias = np.mean((z_test - np.mean(z_preds, axis=1, keepdims=True))**2)\n",
    "    bt_var = np.mean( np.var(z_preds) )\n",
    "    boot_MSE = np.mean(MSEs)\n",
    "    boot_R2 = np.mean(R2s)\n",
    "    \n",
    "    return boot_MSE, boot_R2, bt_err, bt_bias, bt_var\n",
    "from sklearn.utils import resample'''\n",
    "\n",
    "def bootstrap(x, z, x_test, z_test, iterations = 100):\n",
    "    MSEs = np.zeros(iterations) \n",
    "    R2s = np.zeros(iterations) \n",
    "    z_preds = np.zeros((len(z_test), iterations)) \n",
    "    for i in range(iterations):\n",
    "        bt_x, bt_z = resample(x, z)\n",
    "        beta = find_beta(bt_x, bt_z) #Finding beta with new x train and z train\n",
    "        z_pred = x_test @ beta #predict z with x_test\n",
    "        z_preds[:, i] = z_pred.ravel()\n",
    "        z_test = z_test.reshape((-1, 1))\n",
    "        mse = MSE(z_test, z_pred)\n",
    "        r2 = R2(z_test, z_pred) # getting statistics of prediction in current bootstrap\n",
    "        MSEs[i] = mse\n",
    "        R2s[i] = r2\n",
    "    \n",
    "    zpreds = z_preds.ravel()\n",
    "    bt_err = np.mean( np.mean((z_test - z_preds)**2, axis=1, keepdims=True))\n",
    "    bt_bias = np.mean((z_test - np.mean(z_preds, axis=1, keepdims=True))**2)\n",
    "    bt_var = np.mean( np.var(z_preds, axis=1, keepdims=True) )\n",
    "    #bt_var = np.mean( np.var(z_preds) )\n",
    "    boot_MSE = np.mean(MSEs)\n",
    "    boot_R2 = np.mean(R2s)\n",
    "    \n",
    "    return boot_MSE, boot_R2, bt_err, bt_bias, bt_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9af9352f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045730</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>168.734663</td>\n",
       "      <td>-892.685321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043032</td>\n",
       "      <td>0.042953</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>167.023077</td>\n",
       "      <td>-914.888562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.026629</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>175.481618</td>\n",
       "      <td>-951.205261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016853</td>\n",
       "      <td>0.016798</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>178.212096</td>\n",
       "      <td>-932.200402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015364</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>178.810527</td>\n",
       "      <td>-978.835878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>180.633296</td>\n",
       "      <td>-948.337355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>175.708782</td>\n",
       "      <td>-945.800860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>171.756169</td>\n",
       "      <td>-975.552952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>179.642546</td>\n",
       "      <td>-966.418807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>173.109757</td>\n",
       "      <td>-956.538881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>167.200366</td>\n",
       "      <td>-962.543339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012934</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>186.153519</td>\n",
       "      <td>-948.506461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>177.748448</td>\n",
       "      <td>-972.002367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>180.364226</td>\n",
       "      <td>-972.902808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>176.739163</td>\n",
       "      <td>-948.126629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.013436</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>178.341764</td>\n",
       "      <td>-984.271517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012178</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>184.215041</td>\n",
       "      <td>-949.353058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>179.981683</td>\n",
       "      <td>-943.896188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>179.612311</td>\n",
       "      <td>-956.269168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>180.055171</td>\n",
       "      <td>-976.705298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           error      bias  variance         MSE          R2\n",
       "degree                                                      \n",
       "1       0.045730  0.045670  0.000060  168.734663 -892.685321\n",
       "2       0.043032  0.042953  0.000078  167.023077 -914.888562\n",
       "3       0.026687  0.026629  0.000058  175.481618 -951.205261\n",
       "4       0.016853  0.016798  0.000055  178.212096 -932.200402\n",
       "5       0.015364  0.015277  0.000087  178.810527 -978.835878\n",
       "6       0.014467  0.014404  0.000064  180.633296 -948.337355\n",
       "7       0.012913  0.012841  0.000072  175.708782 -945.800860\n",
       "8       0.012520  0.012455  0.000066  171.756169 -975.552952\n",
       "9       0.013784  0.013709  0.000075  179.642546 -966.418807\n",
       "10      0.013541  0.013450  0.000091  173.109757 -956.538881\n",
       "11      0.013566  0.013484  0.000083  167.200366 -962.543339\n",
       "12      0.012934  0.012826  0.000108  186.153519 -948.506461\n",
       "13      0.012710  0.012605  0.000105  177.748448 -972.002367\n",
       "14      0.014417  0.014313  0.000105  180.364226 -972.902808\n",
       "15      0.014184  0.014095  0.000090  176.739163 -948.126629\n",
       "16      0.013546  0.013436  0.000110  178.341764 -984.271517\n",
       "17      0.012178  0.012069  0.000108  184.215041 -949.353058\n",
       "18      0.013344  0.013239  0.000105  179.981683 -943.896188\n",
       "19      0.012794  0.012676  0.000118  179.612311 -956.269168\n",
       "20      0.014013  0.013904  0.000109  180.055171 -976.705298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    error              bias                 variance        \n",
      "0.012912988221478782 >= 0.012840911948501642 + 7.20762729771395e-05 = 0.012912988221478782\n"
     ]
    }
   ],
   "source": [
    "maxdegree = 20\n",
    "scores_OLS_boot = np.zeros((maxdegree, 2))\n",
    "degrees = np.linspace(1, maxdegree, maxdegree, dtype=int)\n",
    "metrics = {'degree': degrees,'error': [], 'bias': [], 'variance': []}\n",
    "\n",
    "for degree in degrees:\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=1/4)\n",
    "    \n",
    "    boot_n = 50\n",
    "\n",
    "    bt_MSE, bt_R2, error, bias, var = bootstrap(X_train,z_train,X_test, z_test, iterations = boot_n) #bootstrapping the z-values to get a resampled set of the 'observed' data\n",
    "    metrics['error'].append(error)\n",
    "    metrics['bias'].append(bias)\n",
    "    metrics['variance'].append(var)\n",
    "    \n",
    "\n",
    "    scores_OLS_boot[degree-1, 0] = bt_MSE\n",
    "    scores_OLS_boot[degree-1, 1] = bt_R2\n",
    "\n",
    "    \n",
    "estimates = pd.DataFrame(scores_OLS_boot, columns=['MSE', 'R2'])\n",
    "bt_results = pd.concat([pd.DataFrame(metrics), estimates], axis = 1)\n",
    "bt_results = bt_results.set_index('degree')\n",
    "display(bt_results)\n",
    "\n",
    "degree7 = bt_results.loc[7]\n",
    "print('    error              bias                 variance        ')\n",
    "print('{} >= {} + {} = {}'.format(degree7['error'], degree7['bias'], degree7['variance'], degree7['bias']+ degree7['variance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45e470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297acd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
