{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ea5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1d2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + np.random.normal(0, 0.1, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d1daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model)**2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f7242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x) # flattens the matrices\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x) #number of x-variables, datapoints\n",
    "    l = int((n+1)*(n+2)/2)     # Number of elements in beta - parameters, features\n",
    "    X = np.ones((N,l)) #Making a matrix of dimentions given by the number of variables and number of parameters\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        q = int((i)*(i+1)/2)\n",
    "        for k in range(i+1):\n",
    "            X[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58cfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_beta(X, z): \n",
    "    XT = X.T\n",
    "    XTXinv = np.linalg.pinv(np.matmul(XT, X))\n",
    "    XTz = np.matmul(XT, z)\n",
    "    beta = np.matmul(XTXinv, XTz)\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad4ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "size = 2000\n",
    "noise = 0.05 # Level of noise\n",
    "x = np.arange(0, 1, 1/size)\n",
    "y = np.arange(0, 1, 1/size)\n",
    "#x, y = np.meshgrid(x,y)\n",
    "\n",
    "z = FrankeFunction(x, y)\n",
    "z += (np.random.randn(size)*noise) #Added noise\n",
    "print(len(x), len(y), len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1a97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def bootstrap(x, z, x_test, z_test, iterations = 100):\n",
    "    MSEs = np.zeros(iterations) \n",
    "    R2s = np.zeros(iterations) \n",
    "    z_preds= []\n",
    "    for i in range(iterations):\n",
    "        bt_x, bt_z = resample(x, z)\n",
    "        beta = find_beta(bt_x, bt_z) #Finding beta with new x train and z train\n",
    "        z_pred = x_test @ beta #predict z with x_test\n",
    "        z_preds.append(z_pred)\n",
    "        mse = MSE(z_test, z_pred)\n",
    "        r2 = R2(z_test, z_pred) # getting statistics of prediction in current bootstrap\n",
    "        MSEs[i] = mse\n",
    "        R2s[i] = r2\n",
    "    \n",
    "    zpreds = np.mean(z_preds)\n",
    "    bt_err = np.mean( np.mean((z_test - z_preds)**2, axis=1, keepdims=True))\n",
    "    bt_bias = np.mean((z_test - np.mean(z_preds, axis=1, keepdims=True))**2)\n",
    "    bt_var = np.mean( np.var(z_preds) )\n",
    "    boot_MSE = np.mean(MSEs)\n",
    "    boot_R2 = np.mean(R2s)\n",
    "    \n",
    "    return boot_MSE, boot_R2, bt_err, bt_bias, bt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af9352f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.188838</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.777123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.195191</td>\n",
       "      <td>0.145637</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.771994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.176688</td>\n",
       "      <td>0.166254</td>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.866375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>0.173921</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018586</td>\n",
       "      <td>0.188231</td>\n",
       "      <td>0.169030</td>\n",
       "      <td>0.018586</td>\n",
       "      <td>0.901235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.190309</td>\n",
       "      <td>0.168344</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.929133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.183244</td>\n",
       "      <td>0.167393</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.930714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013543</td>\n",
       "      <td>0.186423</td>\n",
       "      <td>0.180134</td>\n",
       "      <td>0.013543</td>\n",
       "      <td>0.927352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013560</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>0.177427</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>0.928751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.184486</td>\n",
       "      <td>0.180150</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.930241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.188962</td>\n",
       "      <td>0.170335</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.929194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.188082</td>\n",
       "      <td>0.175262</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.934291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.170639</td>\n",
       "      <td>0.170317</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>0.919921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.177489</td>\n",
       "      <td>0.166564</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.926422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.196268</td>\n",
       "      <td>0.184006</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.927547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.175418</td>\n",
       "      <td>0.159258</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.923284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.179897</td>\n",
       "      <td>0.173395</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.929819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.011809</td>\n",
       "      <td>0.187301</td>\n",
       "      <td>0.179091</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>0.936943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.182863</td>\n",
       "      <td>0.167327</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.935492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.188758</td>\n",
       "      <td>0.161580</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.927961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           error      bias  variance       MSE        R2\n",
       "degree                                                  \n",
       "1       0.042078  0.188838  0.136786  0.042078  0.777123\n",
       "2       0.044492  0.195191  0.145637  0.044492  0.771994\n",
       "3       0.023608  0.176688  0.166254  0.023608  0.866375\n",
       "4       0.016388  0.190349  0.173921  0.016388  0.913900\n",
       "5       0.018586  0.188231  0.169030  0.018586  0.901235\n",
       "6       0.013486  0.190309  0.168344  0.013486  0.929133\n",
       "7       0.012696  0.183244  0.167393  0.012696  0.930714\n",
       "8       0.013543  0.186423  0.180134  0.013543  0.927352\n",
       "9       0.013560  0.190347  0.177427  0.013560  0.928751\n",
       "10      0.012868  0.184486  0.180150  0.012868  0.930241\n",
       "11      0.013379  0.188962  0.170335  0.013379  0.929194\n",
       "12      0.012357  0.188082  0.175262  0.012357  0.934291\n",
       "13      0.013662  0.170639  0.170317  0.013662  0.919921\n",
       "14      0.013057  0.177489  0.166564  0.013057  0.926422\n",
       "15      0.014220  0.196268  0.184006  0.014220  0.927547\n",
       "16      0.013457  0.175418  0.159258  0.013457  0.923284\n",
       "17      0.012624  0.179897  0.173395  0.012624  0.929819\n",
       "18      0.011809  0.187301  0.179091  0.011809  0.936943\n",
       "19      0.011794  0.182863  0.167327  0.011794  0.935492\n",
       "20      0.013596  0.188758  0.161580  0.013596  0.927961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    error              bias                 variance        \n",
      "0.012695638496939608 >= 0.1832443726472326 + 0.1673933600336152 = 0.3506377326808478\n"
     ]
    }
   ],
   "source": [
    "maxdegree = 20\n",
    "scores_OLS_boot = np.zeros((maxdegree, 2))\n",
    "degrees = np.linspace(1, maxdegree, maxdegree, dtype=int)\n",
    "metrics = {'degree': degrees,'error': [], 'bias': [], 'variance': []}\n",
    "\n",
    "for degree in degrees:\n",
    "    X = create_X(x, y, degree)\n",
    "    X_train, X_test, z_train, z_test = train_test_split(X,z,test_size=1/4)\n",
    "    \n",
    "    boot_n = 50\n",
    "\n",
    "    bt_MSE, bt_R2, error, bias, var = bootstrap(X_train,z_train,X_test, z_test, iterations = boot_n) #bootstrapping the z-values to get a resampled set of the 'observed' data\n",
    "    metrics['error'].append(error)\n",
    "    metrics['bias'].append(bias)\n",
    "    metrics['variance'].append(var)\n",
    "    \n",
    "\n",
    "    scores_OLS_boot[degree-1, 0] = bt_MSE\n",
    "    scores_OLS_boot[degree-1, 1] = bt_R2\n",
    "\n",
    "    \n",
    "estimates = pd.DataFrame(scores_OLS_boot, columns=['MSE', 'R2'])\n",
    "bt_results = pd.concat([pd.DataFrame(metrics), estimates], axis = 1)\n",
    "bt_results = bt_results.set_index('degree')\n",
    "display(bt_results)\n",
    "\n",
    "degree7 = bt_results.loc[7]\n",
    "print('    error              bias                 variance        ')\n",
    "print('{} >= {} + {} = {}'.format(degree7['error'], degree7['bias'], degree7['variance'], degree7['bias']+ degree7['variance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45e470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
